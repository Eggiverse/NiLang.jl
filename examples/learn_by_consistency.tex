\section{Learn by consistency}\label{sec:train}
Consider a training that with input $\vx^*$ and output $\vy^*$,
find a set of parameters $\vp_x$ that satisfy $\vy^* = f(\vx^*, \vp_x)$.
In traditional machine learning, we define a loss $\mathcal{L} = {\rm dist}(\vy^*, f(\vx^*, \vp_x))$ and minimize it with gradient $\frac{\partial L}{\partial \vp_x}$. This works only when the target function is locally differentiable.

Here we provide an alternative by making use of reversibility.
We construct a reversible program $\vy, \vp_y =  f_r(\vx, \vp_x)$, where $\vp_x$ and $\vp_y$ are ``parameter'' spaces on the input side and output side.
The algorithm can be summarized as

\begin{algorithm}[H]
    \KwResult{$\vp_x$}
    Initialize $\vx$ to $\vx^*$, parameter space $\vp_x$ to random.\\
    \eIf{$\vp_y$ is \texttt{null}}{
        $\vx, \vp_x = f_r^{-1}(\vy^*)$\\
    }{
        $\vy, \vp_y= f_r(\vx, \vp_x)$\\
        \While{$\vy \not\approx \vy^*$}{
            $\vy = \vy^*$\\
            $\vx, \vp_x = f_r^{-1}(\vy, \vp_y)$.\\
            $\vx = \vx^*$\\
            $\vy, \vp_y= f_r(\vx, \vp_x)$
        }
    }
    \caption{Learn by consistency}\label{algo:train}
\end{algorithm}

Here, $\parameter(\cdot)$ is a function for taking the parameter space.
This algorithm utilizes the self-consistency relation
\begin{equation}\label{eq:selfconsistent}
    \vp_x^* = \parameter(f_r^{-1}(\vy^*, \parameter(f_r(\vx^*, \vp^*_x)))),
\end{equation}

A similar idea of training by consistency is used in self-consistent mean-field theory~\cite{Michael2003} in physics.
Finding the self-consistent relation is crucial to self-consistency based training. Here, the reversibility provides a natural self-consistency relation.
However, it is not a silver bullet; let's consider the following example.

\begin{minipage}{\columnwidth}
\begin{lstlisting}[multicols=2]
@i function f1(y!, x, p!)
    p! += identity(x)
    y! -= exp(x)
    y! += exp(p!)
end

@i function f2(y!, x!, p!)
    p! += identity(x!)
    y! -= exp(x!)
    x! -= log(-y!)
    y! += exp(p!)
end

function train(f)
    loss = Float64[]
    p = 1.6
    for i=1:100
        y!, x = 0.0, 0.3
        @instr f(y!, x, p)
        push!(loss, y!)
        y! = 1.0
        @instr (~f)(y!, x, p)
    end
    loss
end
\end{lstlisting}
\end{minipage}

Functions \texttt{f1} and \texttt{f2} computes $f(x, p) = e^{(p+x)} - e^x$ and stores the output in a new memory \texttt{y!}.
The only difference is \texttt{f2} uncomputes $x$ arithmetically.
The task of the training is to find a $p$ that makes the output value equal to the target value $1$.
After $100$ steps, \texttt{f2} runs into the fixed point with $x$ equal to $1$ upto machine precision.
However, parameters in \texttt{f1} does not change at all.
The training of \texttt{f1} fails because this function actually computes $\texttt{f1}(y, x, p) = y + e^{(p+x)} - e^{x}, x, x+p$, where the training parameter $p$ is completely determined by the parameter space on the output side $x \cup x+p$. As a result, shifting $y$ directly is the only approach to satisfy the consistency relation. On the other side, $\texttt{f2}(y, x, p) = y + e^{(p+x)} - e^x, \tilde{0}, x+p$, the output parameters $\tilde{0} \cup x+p$ can not uniquely determine input parameters $p$ and $x$. Here, we use $\tilde{0}$ to denote the zero with rounding error.

\begin{figure}
    \centerline{\includegraphics[width=0.6\columnwidth,trim={0 0.3cm 0 0},clip]{fig1.pdf}}
    \caption{The output value \texttt{y!} as a function of self-consistent training step.}\label{fig:invtrain}
\end{figure}

By viewing $\vx$ and parameters in $\vp_x$ as variables, we can study the trainability from the information perspective.
\begin{theorem}
    Only if the the conditional entropy $S(\vy|\vp_y)$ is nonzero, algorithm \ref{algo:train} is trainable.
\end{theorem}
\begin{proof}
The above example reveals a fact that training is impossible when output parameters completely determines input parameters (or $S(\vp_x | \vp_y) = 0$).
\begin{align}
    \begin{split}
        S(\vp_x | \vp_y) &= S(\vp_x \cup \vp_y) - S(\vp_y)\\
        &\leq S\left((\vp_x \cup \vx) \cup \vp_y \right) - S(\vp_y),\\
        &\leq S\left((\vp_y \cup \vy) \cup \vp_y\right) - S(\vp_y),\\
    &\leq S(\vy|\vp_y).
    \end{split}
\end{align}
The third line uses the bijectivity $S(\vx \cup \vp_x) = S(\vy \cup \vp_y)$.
This inequality shows that when $S(\vy | \vp_y) = 0$, i.e., the output parameters contain all information in output, the input parameters are entirely determined and the training can not work.
\end{proof}
In the above example, it corresponds to the case $S\left(e^{(x+y)-e^x} | x \cup x + y\right) = 0$ in \texttt{f1}.
The solution is to remove the information redundancy in output parameter space through uncomputing, as shown in \texttt{f2}.
Besides, the Fibonacci example is often used in a reversible language as a tutorial, NiLang implementation could be found in \App{app:fib}.


